knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(ggplot2)
library(dplyr)
library(MTPS)
set.seed(0)
data("HIV")
XX
YY
cutoffs <- c(2, 3, 3, 1.5, 1.5)
#binary outcomes
yBin <- as.matrix(YY)
for (ii in 1:5) {
yBin[, ii] <- (10^yBin[, ii] < cutoffs[ii]) * 1
}
n_folds <- 5
n_repeats <- 50
#(50 repetitions x 1498 samples)
fold_indices <- matrix(NA, nrow = n_repeats, ncol = nrow(XX))
#stratified fold
for (i in 1:n_repeats) {
for (drug in 1:5) {
drug_indices <- which(yBin[, drug] == 1)
non_drug_indices <- which(yBin[, drug] == 0)
fold_indices[i, drug_indices] <- sample(rep(1:n_folds, length.out = length(drug_indices)))
fold_indices[i, non_drug_indices] <- sample(rep(1:n_folds, length.out = length(non_drug_indices)))
}
}
#metrics for evaluation
calculate_metrics <- function(actual, predicted) {
confusion_matrix <- table(actual, predicted)
TP <- confusion_matrix[2, 2]
TN <- confusion_matrix[1, 1]
FP <- confusion_matrix[1, 2]
FN <- confusion_matrix[2, 1]
misclassification_rate <- (FP + FN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
return(c(misclassification_rate, precision, recall, f1_score))
}
drugs <- colnames(yBin)
results <- list()
for (drug in 1:5) {
drug_data <- data.frame(XX, binary_outcome = yBin[, drug])
metrics <- data.frame(
method = character(),
misclassification_rate = numeric(),
precision = numeric(),
recall = numeric(),
f1_score = numeric(),
repetition = integer(),
stringsAsFactors = FALSE
)
for (rep in 1:n_repeats) {
folds <- fold_indices[rep, ]
for (fold in 1:n_folds) {
#training and testing sets
train_data <- drug_data[folds != fold, ]
test_data <- drug_data[folds == fold, ]
#Logistic Regression
logit_model <- glm(binary_outcome ~ ., data = train_data, family = binomial, control = list(maxit = 100))
logit_pred <- ifelse(predict(logit_model, test_data, type = "response") > 0.5, 1, 0)
logit_metrics <- calculate_metrics(test_data$binary_outcome, logit_pred)
#LDA
lda_model <- lda(binary_outcome ~ ., data = train_data)
lda_pred <- predict(lda_model, test_data)$class
lda_metrics <- calculate_metrics(test_data$binary_outcome, lda_pred)
#KNN (K = 2 to 10)
knn_metrics_list <- list()
for (k in 2:10) {
knn_pred <- knn(train = train_data[, -ncol(train_data)],
test = test_data[, -ncol(test_data)],
cl = train_data$binary_outcome, k = k)
knn_metrics <- calculate_metrics(test_data$binary_outcome, knn_pred)
knn_metrics_list[[k - 1]] <- knn_metrics
}
# Store metrics
metrics <- rbind(metrics, data.frame(
method = "Logistic Regression",
misclassification_rate = logit_metrics[1],
precision = logit_metrics[2],
recall = logit_metrics[3],
f1_score = logit_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "LDA",
misclassification_rate = lda_metrics[1],
precision = lda_metrics[2],
recall = lda_metrics[3],
f1_score = lda_metrics[4],
repetition = rep
))
for (k in 2:10) {
metrics <- rbind(metrics, data.frame(
method = paste0("KNN (K=", k, ")"),
misclassification_rate = knn_metrics_list[[k - 1]][1],
precision = knn_metrics_list[[k - 1]][2],
recall = knn_metrics_list[[k - 1]][3],
f1_score = knn_metrics_list[[k - 1]][4],
repetition = rep
))
}
}
}
results[[drugs[drug]]] <- metrics
}
#median metrics for each method
summarize_metrics <- function(metrics) {
metrics %>%
group_by(method) %>%
summarise(
misclassification_rate = median(misclassification_rate),
precision = median(precision),
recall = median(recall),
f1_score = median(f1_score)
)
}
#summary tables for each drug
for (drug in drugs) {
cat("### Drug:", drug, "\n")
summary_table <- summarize_metrics(results[[drug]])
print(summary_table)
cat("\n\n")
}
for (drug in drugs) {
p <- ggplot(results[[drug]], aes(x = method, y = f1_score, fill = method)) +
geom_boxplot() +
labs(title = paste("F1 Scores for", drug), x = "Method", y = "F1 Score") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels
print(p)
}
for (drug in drugs) {
logit_f1 <- results[[drug]] %>% filter(method == "Logistic Regression") %>% pull(f1_score)
lda_f1 <- results[[drug]] %>% filter(method == "LDA") %>% pull(f1_score)
knn_f1 <- results[[drug]] %>% filter(method == "KNN (K=4)") %>% pull(f1_score)
wilcoxon_logit_vs_lda <- wilcox.test(logit_f1, lda_f1, paired = TRUE)
wilcoxon_logit_vs_knn <- wilcox.test(logit_f1, knn_f1, paired = TRUE)
wilcoxon_lda_vs_knn <- wilcox.test(lda_f1, knn_f1, paired = TRUE)
cat("Drug:", drug, "\n")
cat("Logistic Regression vs LDA: p-value =", wilcoxon_logit_vs_lda$p.value, "\n")
cat("Logistic Regression vs KNN: p-value =", wilcoxon_logit_vs_knn$p.value, "\n")
cat("LDA vs KNN: p-value =", wilcoxon_lda_vs_knn$p.value, "\n\n")
}
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(MASS)       # For LDA
library(ggplot2)    # For plotting
library(dplyr)      # For data manipulation
library(rpart)      # For classification tree
library(glmnet)     # For elastic net
# Set seed for reproducibility
set.seed(0)
# Load the HIV dataset
data("HIV")
XX  # Features (genetic sequences)
YY  # Outcomes (drug resistance measurements)
# Define cutoffs for converting continuous outcomes to binary outcomes
cutoffs <- c(2, 3, 3, 1.5, 1.5)
# Convert continuous outcomes to binary outcomes (1 = resistant, 0 = non-resistant)
yBin <- as.matrix(YY)
for (ii in 1:5) {
yBin[, ii] <- (10^yBin[, ii] < cutoffs[ii]) * 1
}
# Define the number of folds and repetitions for cross-validation
n_folds <- 5
n_repeats <- 50
# Create a matrix to store fold indices for each repetition
# Each row corresponds to a repetition, and each column corresponds to a sample
fold_indices <- matrix(NA, nrow = n_repeats, ncol = nrow(XX))
# Generate stratified fold indices for each drug and repetition
# Stratified sampling ensures that each fold has a similar proportion of resistant and non-resistant samples
for (i in 1:n_repeats) {
for (drug in 1:5) {
drug_indices <- which(yBin[, drug] == 1)  # Indices of resistant samples
non_drug_indices <- which(yBin[, drug] == 0)  # Indices of non-resistant samples
# Assign fold indices for resistant and non-resistant samples
fold_indices[i, drug_indices] <- sample(rep(1:n_folds, length.out = length(drug_indices)))
fold_indices[i, non_drug_indices] <- sample(rep(1:n_folds, length.out = length(non_drug_indices)))
}
}
# Function to calculate evaluation metrics (misclassification rate, precision, recall, F1 score)
calculate_metrics <- function(actual, predicted) {
confusion_matrix <- table(actual, predicted)
TP <- confusion_matrix[2, 2]  # True Positives
TN <- confusion_matrix[1, 1]  # True Negatives
FP <- confusion_matrix[1, 2]  # False Positives
FN <- confusion_matrix[2, 1]  # False Negatives
misclassification_rate <- (FP + FN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
return(c(misclassification_rate, precision, recall, f1_score))
}
# List of drugs (columns in yBin)
drugs <- colnames(yBin)
# Initialize a list to store results for each drug
results <- list()
# Loop through each drug and perform cross-validation
for (drug in 1:5) {
# Create a data frame with features (XX) and binary outcome for the current drug
drug_data <- data.frame(XX, binary_outcome = yBin[, drug])
# Initialize a data frame to store metrics for each method
metrics <- data.frame(
method = character(),
misclassification_rate = numeric(),
precision = numeric(),
recall = numeric(),
f1_score = numeric(),
repetition = integer(),
stringsAsFactors = FALSE
)
# Loop through each repetition (50 repetitions)
for (rep in 1:n_repeats) {
folds <- fold_indices[rep, ]  # Get fold indices for the current repetition
# Loop through each fold (5-fold cross-validation)
for (fold in 1:n_folds) {
# Split data into training and testing sets
train_data <- drug_data[folds != fold, ]  # Training data (4 folds)
test_data <- drug_data[folds == fold, ]   # Testing data (1 fold)
# Logistic Regression
logit_model <- glm(binary_outcome ~ ., data = train_data, family = binomial, control = list(maxit = 100))
logit_pred <- ifelse(predict(logit_model, test_data, type = "response") > 0.5, 1, 0)
logit_metrics <- calculate_metrics(test_data$binary_outcome, logit_pred)
# Linear Discriminant Analysis (LDA)
lda_model <- lda(binary_outcome ~ ., data = train_data)
lda_pred <- predict(lda_model, test_data)$class
lda_metrics <- calculate_metrics(test_data$binary_outcome, lda_pred)
# Classification Tree
tree_model <- rpart(binary_outcome ~ ., data = train_data, method = "class")
tree_pred <- predict(tree_model, test_data, type = "class")
tree_metrics <- calculate_metrics(test_data$binary_outcome, tree_pred)
# Elastic Net
enet_model <- cv.glmnet(as.matrix(train_data[, -ncol(train_data)]), train_data$binary_outcome, family = "binomial", alpha = 0.5)
enet_pred <- predict(enet_model, as.matrix(test_data[, -ncol(test_data)]), type = "response")
enet_pred <- ifelse(enet_pred > 0.5, 1, 0)
enet_metrics <- calculate_metrics(test_data$binary_outcome, enet_pred)
# Store metrics for each method
metrics <- rbind(metrics, data.frame(
method = "Logistic Regression",
misclassification_rate = logit_metrics[1],
precision = logit_metrics[2],
recall = logit_metrics[3],
f1_score = logit_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "LDA",
misclassification_rate = lda_metrics[1],
precision = lda_metrics[2],
recall = lda_metrics[3],
f1_score = lda_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "Classification Tree",
misclassification_rate = tree_metrics[1],
precision = tree_metrics[2],
recall = tree_metrics[3],
f1_score = tree_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "Elastic Net",
misclassification_rate = enet_metrics[1],
precision = enet_metrics[2],
recall = enet_metrics[3],
f1_score = enet_metrics[4],
repetition = rep
))
}
}
# Store metrics for the current drug in the results list
results[[drugs[drug]]] <- metrics
}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(MASS)
library(ggplot2)
library(dplyr)
library(rpart)
library(glmnet)
# Set seed for reproducibility
set.seed(0)
# Load the HIV dataset
data("HIV")
XX  # Features (genetic sequences)
YY  # Outcomes (drug resistance measurements)
# Define cutoffs for converting continuous outcomes to binary outcomes
cutoffs <- c(2, 3, 3, 1.5, 1.5)
# Convert continuous outcomes to binary outcomes (1 = resistant, 0 = non-resistant)
yBin <- as.matrix(YY)
for (ii in 1:5) {
yBin[, ii] <- (10^yBin[, ii] < cutoffs[ii]) * 1
}
# Define the number of folds and repetitions for cross-validation
n_folds <- 5
n_repeats <- 50
# Create a matrix to store fold indices for each repetition
# Each row corresponds to a repetition, and each column corresponds to a sample
fold_indices <- matrix(NA, nrow = n_repeats, ncol = nrow(XX))
# Generate stratified fold indices for each drug and repetition
# Stratified sampling ensures that each fold has a similar proportion of resistant and non-resistant samples
for (i in 1:n_repeats) {
for (drug in 1:5) {
drug_indices <- which(yBin[, drug] == 1)  # Indices of resistant samples
non_drug_indices <- which(yBin[, drug] == 0)  # Indices of non-resistant samples
# Assign fold indices for resistant and non-resistant samples
fold_indices[i, drug_indices] <- sample(rep(1:n_folds, length.out = length(drug_indices)))
fold_indices[i, non_drug_indices] <- sample(rep(1:n_folds, length.out = length(non_drug_indices)))
}
}
# Function to calculate evaluation metrics (misclassification rate, precision, recall, F1 score)
calculate_metrics <- function(actual, predicted) {
confusion_matrix <- table(actual, predicted)
TP <- confusion_matrix[2, 2]  # True Positives
TN <- confusion_matrix[1, 1]  # True Negatives
FP <- confusion_matrix[1, 2]  # False Positives
FN <- confusion_matrix[2, 1]  # False Negatives
misclassification_rate <- (FP + FN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * (precision * recall) / (precision + recall)
return(c(misclassification_rate, precision, recall, f1_score))
}
# List of drugs (columns in yBin)
drugs <- colnames(yBin)
# Initialize a list to store results for each drug
results <- list()
# Loop through each drug and perform cross-validation
for (drug in 1:5) {
# Create a data frame with features (XX) and binary outcome for the current drug
drug_data <- data.frame(XX, binary_outcome = yBin[, drug])
# Initialize a data frame to store metrics for each method
metrics <- data.frame(
method = character(),
misclassification_rate = numeric(),
precision = numeric(),
recall = numeric(),
f1_score = numeric(),
repetition = integer(),
stringsAsFactors = FALSE
)
# Loop through each repetition (50 repetitions)
for (rep in 1:n_repeats) {
folds <- fold_indices[rep, ]  # Get fold indices for the current repetition
# Loop through each fold (5-fold cross-validation)
for (fold in 1:n_folds) {
# Split data into training and testing sets
train_data <- drug_data[folds != fold, ]  # Training data (4 folds)
test_data <- drug_data[folds == fold, ]   # Testing data (1 fold)
# Logistic Regression
logit_model <- glm(binary_outcome ~ ., data = train_data, family = binomial, control = list(maxit = 100))
logit_pred <- ifelse(predict(logit_model, test_data, type = "response") > 0.5, 1, 0)
logit_metrics <- calculate_metrics(test_data$binary_outcome, logit_pred)
# Linear Discriminant Analysis (LDA)
lda_model <- lda(binary_outcome ~ ., data = train_data)
lda_pred <- predict(lda_model, test_data)$class
lda_metrics <- calculate_metrics(test_data$binary_outcome, lda_pred)
# Classification Tree
tree_model <- rpart(binary_outcome ~ ., data = train_data, method = "class")
tree_pred <- predict(tree_model, test_data, type = "class")
tree_metrics <- calculate_metrics(test_data$binary_outcome, tree_pred)
# Elastic Net
enet_model <- cv.glmnet(as.matrix(train_data[, -ncol(train_data)]), train_data$binary_outcome, family = "binomial", alpha = 0.5)
enet_pred <- predict(enet_model, as.matrix(test_data[, -ncol(test_data)]), type = "response")
enet_pred <- ifelse(enet_pred > 0.5, 1, 0)
enet_metrics <- calculate_metrics(test_data$binary_outcome, enet_pred)
# Store metrics for each method
metrics <- rbind(metrics, data.frame(
method = "Logistic Regression",
misclassification_rate = logit_metrics[1],
precision = logit_metrics[2],
recall = logit_metrics[3],
f1_score = logit_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "LDA",
misclassification_rate = lda_metrics[1],
precision = lda_metrics[2],
recall = lda_metrics[3],
f1_score = lda_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "Classification Tree",
misclassification_rate = tree_metrics[1],
precision = tree_metrics[2],
recall = tree_metrics[3],
f1_score = tree_metrics[4],
repetition = rep
))
metrics <- rbind(metrics, data.frame(
method = "Elastic Net",
misclassification_rate = enet_metrics[1],
precision = enet_metrics[2],
recall = enet_metrics[3],
f1_score = enet_metrics[4],
repetition = rep
))
}
}
# Store metrics for the current drug in the results list
results[[drugs[drug]]] <- metrics
}
# Function to summarize metrics (median values for each method)
summarize_metrics <- function(metrics) {
metrics %>%
group_by(method) %>%
summarise(
misclassification_rate = median(misclassification_rate),
precision = median(precision),
recall = median(recall),
f1_score = median(f1_score)
)
}
# Print summary tables for each drug
for (drug in drugs) {
cat("### Drug:", drug, "\n")
summary_table <- summarize_metrics(results[[drug]])
print(summary_table)
cat("\n\n")
}
# Plot boxplots of F1 scores for each drug
for (drug in drugs) {
p <- ggplot(results[[drug]], aes(x = method, y = f1_score, fill = method)) +
geom_boxplot() +
labs(title = paste("F1 Scores for", drug), x = "Method", y = "F1 Score") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels
print(p)
}
# Perform Wilcoxon tests to compare F1 scores of new methods with LDA
for (drug in drugs) {
lda_f1 <- results[[drug]] %>% filter(method == "LDA") %>% pull(f1_score)
tree_f1 <- results[[drug]] %>% filter(method == "Classification Tree") %>% pull(f1_score)
enet_f1 <- results[[drug]] %>% filter(method == "Elastic Net") %>% pull(f1_score)
# Compare LDA vs Classification Tree
wilcoxon_lda_vs_tree <- wilcox.test(lda_f1, tree_f1, paired = TRUE)
# Compare LDA vs Elastic Net
wilcoxon_lda_vs_enet <- wilcox.test(lda_f1, enet_f1, paired = TRUE)
# Print p-values
cat("Drug:", drug, "\n")
cat("LDA vs Classification Tree: p-value =", wilcoxon_lda_vs_tree$p.value, "\n")
cat("LDA vs Elastic Net: p-value =", wilcoxon_lda_vs_enet$p.value, "\n\n")
}
