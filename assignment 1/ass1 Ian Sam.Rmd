---
title: "Untitled"
author: "Ian Sam"
date: "2025-01-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(MASS)       
library(class)      
library(ggplot2)    
library(dplyr)      
library(MTPS)       

set.seed(0)

data("HIV")
XX
YY

cutoffs <- c(2, 3, 3, 1.5, 1.5)

#binary outcomes
yBin <- as.matrix(YY)
for (ii in 1:5) {
  yBin[, ii] <- (10^yBin[, ii] < cutoffs[ii]) * 1
}

n_folds <- 5
n_repeats <- 50

#(50 repetitions x 1498 samples)
fold_indices <- matrix(NA, nrow = n_repeats, ncol = nrow(XX))

#stratified fold
for (i in 1:n_repeats) {
  for (drug in 1:5) {
    drug_indices <- which(yBin[, drug] == 1)
    non_drug_indices <- which(yBin[, drug] == 0)
    fold_indices[i, drug_indices] <- sample(rep(1:n_folds, length.out = length(drug_indices)))
    fold_indices[i, non_drug_indices] <- sample(rep(1:n_folds, length.out = length(non_drug_indices)))
  }
}
#metrics for evaluation
calculate_metrics <- function(actual, predicted) {
  confusion_matrix <- table(actual, predicted)
  TP <- confusion_matrix[2, 2]
  TN <- confusion_matrix[1, 1]
  FP <- confusion_matrix[1, 2]
  FN <- confusion_matrix[2, 1]
  
  misclassification_rate <- (FP + FN) / (TP + TN + FP + FN)
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  f1_score <- 2 * (precision * recall) / (precision + recall)
  
  return(c(misclassification_rate, precision, recall, f1_score))
}

drugs <- colnames(yBin)
results <- list()

for (drug in 1:5) {
  drug_data <- data.frame(XX, binary_outcome = yBin[, drug])

  metrics <- data.frame(
    method = character(),
    misclassification_rate = numeric(),
    precision = numeric(),
    recall = numeric(),
    f1_score = numeric(),
    repetition = integer(),
    stringsAsFactors = FALSE
  )
  
  for (rep in 1:n_repeats) {
    folds <- fold_indices[rep, ]
    
    for (fold in 1:n_folds) {
      #training and testing sets
      train_data <- drug_data[folds != fold, ]
      test_data <- drug_data[folds == fold, ]
      
      #Logistic Regression
      logit_model <- glm(binary_outcome ~ ., data = train_data, family = binomial, control = list(maxit = 100))
      logit_pred <- ifelse(predict(logit_model, test_data, type = "response") > 0.5, 1, 0)
      logit_metrics <- calculate_metrics(test_data$binary_outcome, logit_pred)
      
      #LDA
      lda_model <- lda(binary_outcome ~ ., data = train_data)
      lda_pred <- predict(lda_model, test_data)$class
      lda_metrics <- calculate_metrics(test_data$binary_outcome, lda_pred)
      
      #KNN (K = 2 to 10)
      knn_metrics_list <- list()
      for (k in 2:10) {
        knn_pred <- knn(train = train_data[, -ncol(train_data)], 
                        test = test_data[, -ncol(test_data)], 
                        cl = train_data$binary_outcome, k = k)
        knn_metrics <- calculate_metrics(test_data$binary_outcome, knn_pred)
        knn_metrics_list[[k - 1]] <- knn_metrics
      }
      
      # Store metrics
      metrics <- rbind(metrics, data.frame(
        method = "Logistic Regression",
        misclassification_rate = logit_metrics[1],
        precision = logit_metrics[2],
        recall = logit_metrics[3],
        f1_score = logit_metrics[4],
        repetition = rep
      ))
      
      metrics <- rbind(metrics, data.frame(
        method = "LDA",
        misclassification_rate = lda_metrics[1],
        precision = lda_metrics[2],
        recall = lda_metrics[3],
        f1_score = lda_metrics[4],
        repetition = rep
      ))
      
      for (k in 2:10) {
        metrics <- rbind(metrics, data.frame(
          method = paste0("KNN (K=", k, ")"),
          misclassification_rate = knn_metrics_list[[k - 1]][1],
          precision = knn_metrics_list[[k - 1]][2],
          recall = knn_metrics_list[[k - 1]][3],
          f1_score = knn_metrics_list[[k - 1]][4],
          repetition = rep
        ))
      }
    }
  }
  
  results[[drugs[drug]]] <- metrics
}

#median metrics for each method
summarize_metrics <- function(metrics) {
  metrics %>%
    group_by(method) %>%
    summarise(
      misclassification_rate = median(misclassification_rate),
      precision = median(precision),
      recall = median(recall),
      f1_score = median(f1_score)
    )
}

#summary tables for each drug
for (drug in drugs) {
  cat("### Drug:", drug, "\n")
  summary_table <- summarize_metrics(results[[drug]])
  print(summary_table)
  cat("\n\n")
}

for (drug in drugs) {
  p <- ggplot(results[[drug]], aes(x = method, y = f1_score, fill = method)) +
    geom_boxplot() +
    labs(title = paste("F1 Scores for", drug), x = "Method", y = "F1 Score") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels 
  print(p)
}

for (drug in drugs) {
  logit_f1 <- results[[drug]] %>% filter(method == "Logistic Regression") %>% pull(f1_score)
  lda_f1 <- results[[drug]] %>% filter(method == "LDA") %>% pull(f1_score)
  knn_f1 <- results[[drug]] %>% filter(method == "KNN (K=4)") %>% pull(f1_score)
  
  wilcoxon_logit_vs_lda <- wilcox.test(logit_f1, lda_f1, paired = TRUE)
  wilcoxon_logit_vs_knn <- wilcox.test(logit_f1, knn_f1, paired = TRUE)
  wilcoxon_lda_vs_knn <- wilcox.test(lda_f1, knn_f1, paired = TRUE)
  
  cat("Drug:", drug, "\n")
  cat("Logistic Regression vs LDA: p-value =", wilcoxon_logit_vs_lda$p.value, "\n")
  cat("Logistic Regression vs KNN: p-value =", wilcoxon_logit_vs_knn$p.value, "\n")
  cat("LDA vs KNN: p-value =", wilcoxon_lda_vs_knn$p.value, "\n\n")
}
```

